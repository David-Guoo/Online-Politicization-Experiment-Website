{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import sshtunnel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "import datetime\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "from params import question_title_map, bot_detection_title_map, label_map\n",
    "from utils import savefig, get_datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Pythonanywhere\n",
      "Successfully connected to database\n",
      "Data read finished, length: condition 1 length 297, condition 2 length 600, condition 3 length 297\n"
     ]
    }
   ],
   "source": [
    "sshtunnel.SSH_TIMEOUT = 5.0\n",
    "sshtunnel.TUNNEL_TIMEOUT = 5.0\n",
    "\n",
    "with sshtunnel.SSHTunnelForwarder(\n",
    "    ('ssh.pythonanywhere.com'),\n",
    "    ssh_username='Grawi', ssh_password='midgeq-xikFah-gukpu7',\n",
    "    remote_bind_address=('Grawi.mysql.pythonanywhere-services.com', 3306)\n",
    ") as tunnel:\n",
    "    print(\"Successfully connected to Pythonanywhere\")\n",
    "    connection = MySQLdb.connect(\n",
    "        user='Grawi',\n",
    "        passwd='david2202087',\n",
    "        host='127.0.0.1', port=tunnel.local_bind_port,\n",
    "        db='Grawi$Interactive_quiz_database',\n",
    "    )\n",
    "    # Do stuff\n",
    "    print(\"Successfully connected to database\")\n",
    "    \n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        df = [None, None, None]\n",
    "        df[0] = pd.read_sql(\"SELECT * FROM condition_1;\", connection)\n",
    "        df[1] = pd.read_sql(\"SELECT * FROM condition_2;\", connection)\n",
    "        df[2] = pd.read_sql(\"SELECT * FROM condition_3;\", connection)\n",
    "        print(f\"Data read finished, length: condition 1 length {len(df[0])}, condition 2 length {len(df[1])}, condition 3 length {len(df[2])}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    \n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "today = f'{datetime.datetime.today():%Y-%m-%d}'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Pass Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: [[0, 2, 0]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     df[i][\u001b[39m'\u001b[39m\u001b[39madditional_answers\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[i][\u001b[39m'\u001b[39;49m\u001b[39madditional_answers\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(literal_eval)\n\u001b[1;32m      3\u001b[0m     df[i][\u001b[39m'\u001b[39m\u001b[39mnon_ideology_answers\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[i][\u001b[39m'\u001b[39m\u001b[39mnon_ideology_answers\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(literal_eval)\n\u001b[1;32m      4\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/ast.py:99\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[1;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/ast.py:98\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m             \u001b[39mreturn\u001b[39;00m left \u001b[39m-\u001b[39m right\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/ast.py:75\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m operand\n\u001b[0;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/ast.py:66\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_num\u001b[39m(node):\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, Constant) \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(node\u001b[39m.\u001b[39mvalue) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mcomplex\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m         _raise_malformed_node(node)\n\u001b[1;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m node\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/ast.py:63\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_malformed_node\u001b[39m(node):\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmalformed node or string: \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: [[0, 2, 0]]"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    df[i]['additional_answers'] = df[i]['additional_answers'].apply(literal_eval)\n",
    "    df[i]['non_ideology_answers'] = df[i]['non_ideology_answers'].apply(literal_eval)\n",
    "    try:\n",
    "        if hasattr(df[i], 'ideology_answers'):\n",
    "            df[i]['ideology_answers'] = df[i]['ideology_answers'].apply(literal_eval)\n",
    "    except:\n",
    "        None\n",
    "    if hasattr(df[i], 'labels'):\n",
    "        df[i]['labels'] = df[i]['labels'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attention_passed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attention_passed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     id_attention_failed \u001b[39m=\u001b[39m df[i][df[i][\u001b[39m'\u001b[39;49m\u001b[39mattention_passed\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mparticipantId\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor condition \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(id_attention_failed)\u001b[39m}\u001b[39;00m\u001b[39m participants failed attention passed: \u001b[39m\u001b[39m{\u001b[39;00mid_attention_failed\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     df[i] \u001b[39m=\u001b[39m df[i][df[i][\u001b[39m'\u001b[39m\u001b[39mattention_passed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/web_development/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attention_passed'"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    id_attention_failed = df[i][df[i]['attention_passed'] == 0]['participantId'].tolist()\n",
    "    print(f\"For condition {i + 1}, {len(id_attention_failed)} participants failed attention passed: {id_attention_failed}\")\n",
    "    df[i] = df[i][df[i]['attention_passed'] == True]\n",
    "    columns_to_drop = ['assignmentId', 'projectId', 'attention_passed', 'total_time', 'identity_choices', 'ideologies', 'submit_time']\n",
    "    df[i].drop(columns_to_drop, inplace=True, axis=1)\n",
    "    print(f\"There are {len(df[i])} valid data collected\\n\")\n",
    "    df[i].set_index('participantId', inplace=True)\n",
    "df[0].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For condition 1, there are 33.22% participants who detected at least one bot\n",
      "For condition 1, there are 14.19% participants who detected one bot\n",
      "For condition 1, there are 19.03% participants who detected at two bots\n",
      "For condition 2, there are 29.40% participants who detected at least one bot\n",
      "For condition 2, there are 12.82% participants who detected one bot\n",
      "For condition 2, there are 16.58% participants who detected at two bots\n",
      "For condition 3, there are 29.86% participants who detected at least one bot\n",
      "For condition 3, there are 14.24% participants who detected one bot\n",
      "For condition 3, there are 15.62% participants who detected at two bots\n"
     ]
    }
   ],
   "source": [
    "def get_bot_detection_num(detection):\n",
    "    first = detection // 10\n",
    "    second = detection % 10\n",
    "    return int(first == 3) + int(second == 3)\n",
    "\n",
    "ratio_at_least_one_bot_detected = []\n",
    "ratio_one_bot_detected = []\n",
    "ratio_two_bots_detected = []\n",
    "\n",
    "for i in range(3):\n",
    "    df[i]['bot_detection_num'] = df[i]['bot_detected'].apply(get_bot_detection_num)\n",
    "    ratio_at_least_one_bot_detected.append(((df[i]['bot_detection_num'] >= 1).sum()) / (len(df[i])))\n",
    "    ratio_one_bot_detected.append(((df[i]['bot_detection_num'] == 1).sum()) / (len(df[i])))\n",
    "    ratio_two_bots_detected.append(((df[i]['bot_detection_num'] == 2).sum()) / (len(df[i])))\n",
    "    print(f\"For condition {i + 1}, there are {ratio_at_least_one_bot_detected[i]:.2%} participants who detected at least one bot\")\n",
    "    print(f\"For condition {i + 1}, there are {ratio_one_bot_detected[i]:.2%} participants who detected one bot\")\n",
    "    print(f\"For condition {i + 1}, there are {ratio_two_bots_detected[i]:.2%} participants who detected at two bots\")\n",
    "    df[i].drop(['reason', 'bot_detection_num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whether labels are consistent until the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_pairs(row):\n",
    "#     ret = [0, 0, 0]\n",
    "#     if 'ideology_answers' in row.index:\n",
    "#         for ideology_answer in row['ideology_answers']:\n",
    "#             for i in range(3):\n",
    "#                 try:\n",
    "#                     ret[i] += abs(ideology_answer['answers'][i] - ideology_answer['answers'][1])\n",
    "#                 except Exception as e:\n",
    "#                     None\n",
    "    \n",
    "#     new_rows = []\n",
    "#     for idx in range(3):\n",
    "#         bot_detection = False\n",
    "#         if idx == 0:\n",
    "#             bot_detection = (row['bot_detected'] // 10) == 3\n",
    "#         elif idx == 2:\n",
    "#             bot_detection = (row['bot_detected'] % 10) == 3\n",
    "\n",
    "#         new_row = {\n",
    "#             \"participantId\": row.name,\n",
    "#             \"idx\": idx,\n",
    "#             \"bot_detection\": bot_detection, \n",
    "#             \"reported_ideology\": row['additional_answers'][0][idx]\n",
    "#         }\n",
    "\n",
    "#         if \"labels\" in row.index:\n",
    "#             new_row[\"labels\"] = row['labels'][idx]\n",
    "#         if \"ideology_answers\" in row.index:\n",
    "#             new_row['answer_distance'] = ret[idx]\n",
    "        \n",
    "#         new_rows.append(new_row)\n",
    "#     return pd.DataFrame(new_rows)\n",
    "\n",
    "# df_pairs = [None, None, None]\n",
    "# for i in range(3):\n",
    "#     list_of_df_pairs = df[i].apply(generate_pairs, axis=1).tolist()\n",
    "#     df_pairs[i] = pd.concat(list_of_df_pairs, ignore_index=True)\n",
    "#     df_pairs[i].set_index(\"participantId\", inplace=True)\n",
    "#     df_pairs[i].to_csv(f\"data/condition_{i + 1}-pair.csv\")\n",
    "\n",
    "# df_label_consistency = pd.concat([df_pairs[1], df_pairs[2]])\n",
    "# df_label_consistency.head()\n",
    "\n",
    "# def ideology_is_consistent(row):\n",
    "#     labels = set(row['labels'])\n",
    "#     reported_ideology = row['reported_ideology']\n",
    "#     if len(set([label_map[\"Conservative\"], label_map[\"Somewhat conservative\"], label_map[\"Liberal\"], label_map[\"Somewhat liberal\"]]).intersection(labels)) == 0:\n",
    "#         return True\n",
    "    \n",
    "#     if label_map[\"Conservative\"] in row['labels'] or label_map[\"Somewhat conservative\"] in row['labels']:\n",
    "#         if reported_ideology > 0:\n",
    "#             return True\n",
    "#     if label_map[\"Liberal\"] in row['labels'] or label_map[\"Somewhat liberal\"] in row['labels']:\n",
    "#         if reported_ideology < 0:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "# df_label_consistency['label_consistency'] = df_label_consistency.apply(ideology_is_consistent, axis=1)\n",
    "\n",
    "# print(f\"Label consistency rate: {df_label_consistency['label_consistency'].mean():.2%}\")\n",
    "# print(f\"Correlation: {pearsonr(df_label_consistency['answer_distance'], df_label_consistency['ideology_distance'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_answer_distances(ideology_answers):\n",
    "#     if type(ideology_answers) != list:\n",
    "#         return [0, 0]\n",
    "#     ret = [0, 0]\n",
    "#     for ideology_answer in ideology_answers:\n",
    "#         # print(ideology_answer, type(ideology_answer))\n",
    "#         ret[0] += abs(ideology_answer['answers'][0] - ideology_answer['answers'][1])\n",
    "#         ret[1] += abs(ideology_answer['answers'][2] - ideology_answer['answers'][1])\n",
    "#     return ret\n",
    "\n",
    "# def get_ideology_distances(additional_answers):\n",
    "#     return [abs(additional_answers[0][0] - additional_answers[0][1]), abs(additional_answers[0][2] - additional_answers[0][1])]\n",
    "\n",
    "# df_answer_analysis['answer_distances'] = df_answer_analysis['ideology_answers'].apply(get_answer_distances)\n",
    "# df_answer_analysis['ideology_distances'] = df_answer_analysis['additional_answers'].apply(get_ideology_distances)\n",
    "# # df_answer_analysis.drop(['ideology_answers', 'additional_answers', 'bot_same_ideology', 'ideologies'], axis=1, inplace=True)\n",
    "# df_answer_analysis.head()\n",
    "# df_bots_exploded = df_answer_analysis.explode(['answer_distances', 'ideology_distances'])\n",
    "# df_bots_exploded['answer_distances'] = df_bots_exploded['answer_distances'].astype(int)\n",
    "# df_bots_exploded['ideology_distances'] = df_bots_exploded['ideology_distances'].astype(float)\n",
    "# df_bots_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearsonr(df_bots_exploded['answer_distances'], df_bots_exploded['ideology_distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_affection(labels, type):\n",
    "#     bot_labels = set(row['labels'])\n",
    "#     if type == \"competence\":\n",
    "#         good_label_num = len(set([label_map['Competent']]).intersection(bot_labels))\n",
    "#         bad_label_num = len(set([label_map['Incompetent']]).intersection(bot_labels))\n",
    "#     elif type == \"warmth\":\n",
    "#         good_label_num = len(set([label_map['Kind']]).intersection(bot_labels))\n",
    "#         bad_label_num = len(set([label_map['Indifferent']]).intersection(bot_labels))  \n",
    "#     return good_label_num - bad_label_num\n",
    "\n",
    "\n",
    "# for condition in range(3):\n",
    "#     df[condition]['condition'] = condition + 1\n",
    "    \n",
    "# df_total = pd.concat([df[condition] for condition in range(3)])\n",
    "# df_total.reset_index(inplace=True)\n",
    "# df_total = df_total.explode(['additional_answers'])\n",
    "# df_total['valid_ideologies'] = df_total['additional_answers'].apply(lambda x: int(x[0]) != 0 or int(x[1]) != 0 or int(x[2]) != 0)\n",
    "# df_exploded = df_total.explode(['non_ideology_answers'])\n",
    "# df_exploded['bot_detection'] = df_exploded['bot_detected'].apply(lambda num: [num // 10 == 3, False, num % 10 == 3])\n",
    "# df_exploded['answer'] = df_exploded['non_ideology_answers'].apply(lambda x: x['answers'])\n",
    "# df_exploded['idx_of_question'] = df_exploded['non_ideology_answers'].apply(lambda x: x['idx_of_question'])\n",
    "# df_exploded['who_answers_first'] = df_exploded['non_ideology_answers'].apply(lambda x: x['who_answers_first'])\n",
    "# df_exploded['ideology'] = df_exploded['additional_answers']\n",
    "# df_exploded['who'] = np.nan\n",
    "# df_exploded['who'] = df_exploded['who'].apply(lambda x: [0, 1, 2])\n",
    "# df_exploded['labels'] = df_exploded['labels'].apply(lambda x: [None, None, None] if isinstance(pd.isna(x), bool) else x)\n",
    "# df_each_subject = df_dropped.explode(['ideology', 'answer', 'bot_detection', 'labels', 'who'])\n",
    "# df_dropped = df_exploded.drop(['bot_detected', 'non_ideology_answers', 'ideology_answers', 'additional_answers'], axis=1)\n",
    "# df_each_subject = df_each_subject[['participantId', 'idx_of_question', 'who', 'ideology', 'answer', 'condition', 'who_answers_first', 'bot_detection', 'labels', 'valid_ideologies']]\n",
    "# df_reindexed = df_each_subject.set_index(\"participantId\")\n",
    "# df_reindexed.to_csv(\"data/condition.csv\")\n",
    "# df_reindexed.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Average Distances and Plot The Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_answer = [None, None, None]\n",
    "\n",
    "def detect_first_answering_bot(row):\n",
    "    if row['who_answers_first'] == 0:\n",
    "        return (row['bot_detected'] // 10) == 3\n",
    "    else:\n",
    "        return (row['bot_detected'] % 10) == 3\n",
    "\n",
    "def get_ideology_distance(row):\n",
    "    who_answers_first = row['who_answers_first']\n",
    "    additional_answers = row['additional_answers'][0]\n",
    "    if who_answers_first != 1:\n",
    "        return [abs(additional_answers[who_answers_first] - additional_answers[1])]\n",
    "    else:\n",
    "        return [abs(additional_answers[0] - additional_answers[1]), abs(additional_answers[2] - additional_answers[1])]\n",
    "\n",
    "def get_target_ideology(row):\n",
    "    ideologies = row['additional_answers'][0]\n",
    "    if row['who_answers_first'] == 1:\n",
    "        return [float(ideologies[0]), float(ideologies[2])]\n",
    "    else:\n",
    "        return [float(ideologies[row['who_answers_first']])]\n",
    "\n",
    "def calculate_answer_distance(row):\n",
    "    if row['who_answers_first'] != 1:\n",
    "        return abs(row['answers'][1] - row['answers'][row['who_answers_first']])\n",
    "    else:\n",
    "        # return (row['answers'][1] ** 2 + 9) / 6\n",
    "        return abs(row['answers'][1] - (np.random.random() * 6 - 3))\n",
    "\n",
    "def get_target_answer(row):\n",
    "    if row['who_answers_first'] == 1:\n",
    "        return [np.random.uniform(-3, 3), np.random.uniform(-3, 3)]\n",
    "    else:\n",
    "        return [row['answers'][row['who_answers_first']]]\n",
    "    \n",
    "def get_affection(row, type):\n",
    "    bot_labels = set(row['labels'])\n",
    "    if type == \"competence\":\n",
    "        good_label_num = len(set([label_map['Competent']]).intersection(bot_labels))\n",
    "        bad_label_num = len(set([label_map['Incompetent']]).intersection(bot_labels))\n",
    "    elif type == \"warmth\":\n",
    "        good_label_num = len(set([label_map['Kind']]).intersection(bot_labels))\n",
    "        bad_label_num = len(set([label_map['Indifferent']]).intersection(bot_labels))  \n",
    "    return good_label_num - bad_label_num\n",
    "\n",
    "def has_SCM_label(labels):\n",
    "    if len(set([4, 5]).intersection(set(labels))) > 0 or len(set([8, 9]).intersection(set(labels))) > 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for i in range(3):\n",
    "    df[i]['ideology_all_zeros'] = df[i]['additional_answers'].apply(lambda x: x[0][0] == 0 and x[0][1] == 0 and x[0][2] == 0)\n",
    "    each_answer[i] = df[i].explode('non_ideology_answers')\n",
    "    each_answer[i]['answers'] = each_answer[i].apply(lambda row: row['non_ideology_answers']['answers'], axis=1)\n",
    "    each_answer[i]['idx_of_question'] = each_answer[i].apply(lambda row: row['non_ideology_answers']['idx_of_question'], axis=1)\n",
    "    each_answer[i]['who_answers_first'] = each_answer[i].apply(lambda row: row['non_ideology_answers']['who_answers_first'], axis=1)\n",
    "    each_answer[i]['bot_detection'] = each_answer[i].apply(detect_first_answering_bot, axis=1)\n",
    "    each_answer[i]['ideology'] = each_answer[i]['additional_answers'].apply(lambda x: float(x[0][1]))\n",
    "    each_answer[i]['bot_ideology'] = each_answer[i].apply(get_target_ideology, axis=1)\n",
    "    each_answer[i]['ideology_distance'] = each_answer[i].apply(get_ideology_distance, axis=1)\n",
    "    each_answer[i]['answer'] = each_answer[i]['answers'].apply(lambda x: x[1])\n",
    "    each_answer[i]['bot_answer'] = each_answer[i].apply(get_target_answer, axis=1)\n",
    "    each_answer[i]['answer_distance'] = each_answer[i].apply(calculate_answer_distance, axis=1)\n",
    "\n",
    "    each_answer[i].drop(['non_ideology_answers', 'bot_detected', 'additional_answers', 'answers'], axis=1, inplace=True)\n",
    "    \n",
    "    if 'ideology_answers' in each_answer[i].columns:\n",
    "        each_answer[i].drop(['ideology_answers'], axis=1, inplace=True)\n",
    "\n",
    "for i in [1, 2]:\n",
    "    each_answer[i]['labels'] = each_answer[i].apply(lambda row: row['labels'][row['who_answers_first']], axis=1)\n",
    "    each_answer[i]['affection_competence'] = each_answer[i].apply(get_affection, axis=1, type=\"competence\")\n",
    "    each_answer[i]['affection_warmth'] = each_answer[i].apply(get_affection, axis=1, type=\"warmth\")\n",
    "    each_answer[i].drop(['labels'], axis=1, inplace=True)\n",
    "\n",
    "for i in range(3):\n",
    "    each_answer[i]['condition'] = i + 1\n",
    "\n",
    "condition_data = pd.concat([each_answer[i] for i in range(3)])\n",
    "condition_data.to_csv(\"data/condition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.10086282182031807, pvalue=1.0137154763034107e-06)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare = each_answer[1].loc[each_answer[1]['who_answers_first'] != 1]\n",
    "pearsonr(df_compare['ideology_distance'], df_compare['answer_distance'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c02eb120b4c6e68511951ac3fb0ac091494f4cf9058e9fbc2a11fb1e6da4036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
